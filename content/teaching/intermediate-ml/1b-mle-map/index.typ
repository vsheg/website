#import "../template.typ": *
#show: template

= Semi-probabilistic model

== Probabilistic framework
Let the data be generated by a joint distribution of two random variables: a feature
vector $bold(x) tilde X$ and a class label $y tilde Y$ from a given parametric family ($bold(theta)$ is
the parameter), with each observation being independent:

$ bold(x), y tilde f_(X,Y) (bold(x), y|bold(theta)) tilde (X times Y)^ell, quad bold(x) in RR^k, y = 1..N $

Given a training sample, we need to estimate the parameter values and build a predictive
model:

$ hat(y)(bold(x)) = a_bold(theta)(bold(x)) $

== Model
We will use the formalism of *semi-probabilistic models*, i.e., we will consider $X$ values
as fixed and $Y$ values as variables in the model. In other words, as a predictive model,
we will build a probability distribution $f_Y (y|bold(x)^*,bold(theta))$ for the random
variable $Y$, parameterized by the data $bold(x)^* in X^ell$ and the distribution shape
parameters $bold(theta)$

== Likelihood function
Let's write the joint distribution for all observed points as a product of independent
distributions:
#margin[ $
    f(x,y|theta) &= f(x,y,theta) / f(theta) = (f(y|x,theta) \/ f(x, theta)) / f(theta) \
                 &= f(y|x,theta) / (f(theta) dot f(x,theta)) = f(y|x,theta) / cancel(f(x|theta))
  $ ]
$
  L(bold(theta))
    &= product_((bold(x)^*, y^*) in (X, Y)^ell) ub(f (bold(x) = bold(x)^*, y = y^*|bold(theta)), "likelihood") \
    &= product_((bold(x)^*, y^*) in (X, Y)^ell) ob(
    f_Y (y = y^*|bold(x)=bold(x)^*, bold(theta)),
    "predictive model" a_bold(theta) (bold(x)),

  ) / ub(cancel(f_(X) (bold(x) = bold(x)^*|bold(theta))), "prior distribution") \
$

Applying the logarithm to the likelihood function, we obtain the log-likelihood function:

$
  ell(bold(theta)) = sum_((bold(x)^*, y^*) in (X, Y)^ell) ln Pr (y = y^*|bold(x)=bold(x)^*,bold(theta))
  -> max_bold(theta)
$

== Parameter estimation
Thus, we can find the parameter values $bold(theta)$ and use them in the conditional
distribution for prediction:

$ a_hat(bold(theta)) (bold(x)') = ub(
  f_Y (y|bold(x)=bold(x)',bold(theta) = hat(bold(theta))),
  "distribution of" Y "must be chosen",

) $

#margin[The prior distribution $f_X (bold(x)|bold(theta))$ is canceled out from the product above.

  - The maximum likelihood method considers the prior distribution of $x$ unknown and
  unimportant (unlike in MAP), focusing solely on the conditional distribution $Pr[y|bold(x)^*,bold(theta)]$ which
  serves as a model for building the algorithm $hat(y) = a(x)$.

  - Generally, when the chosen prior distribution is parameter-independent ($f_{X}(bold(x)|bold(theta)) equiv f_{X}(x)$),
  it naturally cancels out since it remains constant for fixed $bold(x)^*$ and does not
  depend on $bold(theta)$.]

== Cross-entropy loss
From summing over specific points $y^* in Y^ell$, we can transition to summing over all
possible values $y' = 1..N$, assuming zero probability for point $y^*$ belonging to
another class $y' != y^*$ and defining $0 dot ln 0 equiv 0$ by definition.

$
  ell &= sum_(bold(x) in X^ell) sum_(y' in supp Y) Ind(y'=y^*) dot ln Pr [y = y'|bold(x)=bold(x)^*,bold(theta)] \
      &tilde sum_(bold(x) in X^ell) sum_(y' in supp Y) ub(Pr [y = y'|bold(x)=bold(x)^*,bold(theta)], "smooth approximation of" Ind()) dot ln Pr [y = y'|bold(x)=bold(x)^*,bold(theta)] -> min_bold(theta)
$

This is cross-entropy loss, which can be used if the model predicts *probabilities of
belonging to each class*.